# rock-paper-scissors
This project is an implementation for the famous game (Rock-Paper-Scissors) using deep learning.

## Trainig CNN
Dataset used for training:
https://www.kaggle.com/drgfreeman/rockpaperscissors

model architecture and training process will be found in the notebook "RPS.ipynb" 

Training Accuracy: 96.12%.

## How to play
1. Attach a webcam to your device
in my case I've used my Android mobile as a webcam by downloading 'DroidCam' on both my mobile from Play Store and on my laptop from this link https://www.dev47apps.com/droidcam/windows/

2. Put your webcam or mobile in a fixed place
3. Download architecture pretrained weights from this link: https://drive.google.com/file/d/1RqcdFtfqiPesr7S5G3ICds4ArkDTxvMt/view?usp=sharing
4. Copy the downloaded weights to 'output' folder
5. Run 'game.py'
6. Put your hand in the FOV of the camera and make one of the three moves.
7. Press 'Space Bar' let the computer randomly choose one of the three moves and compare it to your move
8. Press 'Space Bar' again to get back to the idle mode.

## Output example
![paper_vs_scissors](https://user-images.githubusercontent.com/42648840/95873196-f5b8ec00-0d6f-11eb-87d8-55a4cbae1ed3.PNG)

![scissors_vs_rock](https://user-images.githubusercontent.com/42648840/95873320-1a14c880-0d70-11eb-9efb-0b41e8a2e807.PNG)

![paper_vs_paper](https://user-images.githubusercontent.com/42648840/95873400-30bb1f80-0d70-11eb-9eb0-bbaca1356a76.PNG)

### Youtube Video for the project
https://youtu.be/hnEAQR18IPg
